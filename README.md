# word-embedding
A gentle introduction to word embedding <br>

Find explanation [here](https://dreamtechthefuture.wordpress.com/2018/10/18/word-embedding/)<br>

Find my pretrained gensim word2vec models -<br>
1. (500 dimentional word vectors) Without replacing '\n' (newline) with "<eos>" in the PTB dataset [here](https://drive.google.com/open?id=1r-ZOyFC-K8un4t2k8k0HJzue_5Sh7Qhq)
2. (500 dimentional word vectors) Replacing '\n' with "<eos>" in the PTB dataset [here](https://drive.google.com/open?id=1cEMID9g-k_sz-V6M1OKWY2-EU8Fighj_) 

Find Google's pretrained word embeddings [here](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing).<br>
Word of caution : You can only use the value of the word embeddings, cant train it
